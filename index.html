<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8" />
  <title>Iniciar Sesi칩n - Bookshop</title>
  <link rel="stylesheet" href="estilos.css" />
</head>
<body>
  <div class="container">
    <div class="form-container">
      <h1>Bookshop</h1>
      <h2>Inicio de sesi칩n</h2>

      <button onclick="iniciarEscaneoFacial()">Iniciar escaneo facial</button>
      <button onclick="mostrarFormulario()">Iniciar con correo y contrase침a</button>

      <a href="registro.html">
        <button>游녻 Registrarme</button>
      </a>

      <form id="manualLoginForm" style="display: none; margin-top: 20px;">
        <label>Correo:</label>
        <input type="email" name="correo" required />

        <label>Contrase침a:</label>
        <input type="password" name="contrasena" required />

        <button type="submit">Ingresar</button>
      </form>
    </div>

    <div class="camera-container">
        <video id="video" width="320" height="240" autoplay muted></video>
        <canvas id="overlay"></canvas>
        <p class="note">*Vea directamente a la c치mara para el escaneo facial. Si no es posible, use su correo y contrase침a.</p>
    </div>
  </div>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface@0.0.7/dist/blazeface.min.js"></script>

    <!-- MediaPipe FaceMesh + helpers desde jsDelivr -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>

    <script>
    // Elementos
    const video = document.getElementById('video');
    const canvas = document.getElementById('overlay');
    const ctx = canvas.getContext('2d');
    const startBtn = document.getElementById('startBtn');
    const stopBtn = document.getElementById('stopBtn');

    let camera = null;
    let lastTime = performance.now();
    let frameCount = 0;

    // INICIALIZAR FaceMesh de MediaPipe
    const faceMesh = new FaceMesh({
        locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`
    });

    faceMesh.setOptions({
        maxNumFaces: 2,
        refineLandmarks: true, // obtiene puntos extra alrededor de ojos/labios
        minDetectionConfidence: 0.6,
        minTrackingConfidence: 0.5
    });

    faceMesh.onResults(onResults);

    // Opcional: cargar BlazeFace (TensorFlow.js) para pre-detecci칩n
    let blazefaceModel = null;

    async function loadBlazeFace(){
        try{
            blazefaceModel = await blazeface.load();
            console.log('BlazeFace cargado');
        }catch(e){
            console.warn('No se pudo cargar BlazeFace (opcional):', e);
        }
    }

    loadBlazeFace();

    function resizeCanvasToVideo(){
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        canvas.style.width = video.clientWidth + 'px';
        canvas.style.height = video.clientHeight + 'px';
    }

    async function onResults(results){
        // Dibujar video en canvas (opcional - lo dejamos transparente para overlay limpio)
        ctx.clearRect(0,0,canvas.width,canvas.height);

        if(results.multiFaceLandmarks && results.multiFaceLandmarks.length){
            for(const landmarks of results.multiFaceLandmarks){
                // Dibujar puntos y conexiones usando drawing_utils de MediaPipe
                drawConnectors(ctx, landmarks, FaceMesh.FACEMESH_TESSELATION, {lineWidth:1});
                drawConnectors(ctx, landmarks, FaceMesh.FACEMESH_RIGHT_EYE, {lineWidth:2});
                drawConnectors(ctx, landmarks, FaceMesh.FACEMESH_LEFT_EYE, {lineWidth:2});
                drawConnectors(ctx, landmarks, FaceMesh.FACEMESH_LIPS, {lineWidth:2});
                for(let i=0;i<landmarks.length;i++){
                const x = landmarks[i].x * canvas.width;
                const y = landmarks[i].y * canvas.height;
                ctx.beginPath();
                ctx.arc(x,y,1.2,0,2*Math.PI);
                ctx.fillStyle = 'rgba(0,200,255,0.9)';
                ctx.fill();
                }
            }
        }
    }

    async function startCamera(){
        // Pide permisos y configura video
        const stream = await navigator.mediaDevices.getUserMedia({ video: { width:1280, height:720 }, audio:false });
        video.srcObject = stream;

        await video.play();
        resizeCanvasToVideo();

        // Usar MediaPipe Camera util para enviar frames a FaceMesh
        camera = new Camera(video, {
        onFrame: async () => {
            // Si quieres usar BlazeFace como pre-check, puedes hacerlo aqu칤 (opcional):
            // if(blazefaceModel){ const predictions = await blazefaceModel.estimateFaces(video, false); /* puedes usar predictions */ }

            await faceMesh.send({image: video});
        },
        width: video.videoWidth,
        height: video.videoHeight
        });
        camera.start();

        startBtn.disabled = true;
        stopBtn.disabled = false;
    }

    function stopCamera(){
        if(camera) camera.stop();
        const tracks = video.srcObject ? video.srcObject.getTracks() : [];
        tracks.forEach(t => t.stop());
        video.srcObject = null;
        startBtn.disabled = false;
        stopBtn.disabled = true;
        ctx.clearRect(0,0,canvas.width,canvas.height);
    }

    document.addEventListener("DOMContentLoaded", () => {
        startCamera().catch(err => {
            alert("Error accediendo a la c치mara: " + err.message)
        });
    })

    // startBtn.addEventListener('click', () => startCamera().catch(err=>{alert('Error accediendo a la c치mara: '+err.message)}));
    // stopBtn.addEventListener('click', stopCamera);

    // Reajustar canvas cuando cambie el tama침o
    window.addEventListener('resize', () => { if(video.videoWidth) resizeCanvasToVideo(); });

    // Nota: para ejecutar localmente sirve usar un servidor (p. ej. `npx http-server` o la extensi칩n Live Server de VSCode) porque algunos navegadores exigen contexto seguro para getUserMedia.
    </script>
</body>
</html>
